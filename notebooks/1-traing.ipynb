{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "def load_config():\n",
    "    \"\"\"To load configuration from file .env\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "\n",
    "def connect_boto3():\n",
    "    \"\"\"\"\"\"\n",
    "    s3 = boto3.resource(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv(\"ACCESS_KEY\"),\n",
    "        aws_secret_access_key=os.getenv(\"SECRET_ACCESS_KEY\")\n",
    "    )\n",
    "    return s3\n",
    "\n",
    "def read_csv_to_df(bucket, key:str, encoding = \"utf-8\", sep = ',') -> pd.DataFrame:\n",
    "    \"\"\"read csv to dataframe from s3 bucket\n",
    "\n",
    "    Args:\n",
    "        bucket (_type_): s3 bucket\n",
    "        key (str): file's key in s3 bucket\n",
    "        encoding (str, optional): type of encoding. Defaults to \"utf-8\".\n",
    "        sep (str, optional): sep to read csv file. Defaults to ','.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "    csv_obj = bucket.Object(key=key).get().get(\"Body\").read().decode(encoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter = sep)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def write_df_to_s3(bucket, df, key):\n",
    "    \"\"\"Write dataframe to s3 bucket\"\"\"\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "def write_df_to_s3_csv(bucket, df, key):\n",
    "    out_buffer = StringIO()\n",
    "    df.to_csv(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "def list_files_in_prefix(bucket, prefix):\n",
    "    \"\"\"list file form s3 bucket\"\"\"\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer\n",
    "## We have in this layer three stages Extract Transform Load\n",
    "\n",
    "def extract(bucket, date_list):\n",
    "    \"\"\"Extract data from files cvs in s3 bucket\n",
    "\n",
    "    Args:\n",
    "        bucket (_type_): _description_\n",
    "        date_list (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
    "    df_data = pd.concat([read_csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
    "    return df_data\n",
    "\n",
    "def transform_report_one(df, columns, arg_date):\n",
    "    \"\"\"\"\"\"\n",
    "    df = df[columns]\n",
    "    df['OpeningPrice'] = (\n",
    "        df\n",
    "        .sort_values(by=['Time'])\n",
    "        .groupby(['ISIN', 'Date'])['StartPrice']\n",
    "        .transform('first')\n",
    "    )\n",
    "    df['ClosingPrice'] = (\n",
    "        df\n",
    "        .sort_values(by=['Time'])\n",
    "        .groupby(['ISIN', 'Date'])['StartPrice']\n",
    "        .transform('last')\n",
    "    )\n",
    "\n",
    "    df = df.groupby([\"ISIN\", \"Date\"], as_index=False)\\\n",
    "            .agg(\n",
    "                opening_price_eur=('OpeningPrice', 'min'),\n",
    "                closing_price_eur=('ClosingPrice', 'min'),\n",
    "                minimun_price_eur=('MinPrice', 'min'),\n",
    "                maxmun_price_eur=('MaxPrice', 'max'),\n",
    "                daily_traded_volumne=('TradedVolume', 'sum')\n",
    "            )\n",
    "\n",
    "    df[\"prev_closing_price\"] = (\n",
    "        df.sort_values(by=['Date'])\n",
    "            .groupby('ISIN')['closing_price_eur'].shift(1)\n",
    "    )\n",
    "\n",
    "    df[\"change_prev_closing_%\"] = (\n",
    "        (df['closing_price_eur'] - df['prev_closing_price']) / df['prev_closing_price'] * 100\n",
    "    )\n",
    "\n",
    "    df.drop(columns=\"prev_closing_price\", inplace=True)\n",
    "    df = df.round(decimals=2)\n",
    "    df = df[df['Date'] >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, target_key, trg_format, meta_file, extract_date_list, src_format):\n",
    "    \"\"\"\"\"\"\n",
    "    key = f\"{target_key}{datetime.today().strftime('%Y%m%d_%H%M%S')}{trg_format}\"\n",
    "    write_df_to_s3(bucket, df, key)\n",
    "    update_meta_file(bucket, meta_file, extract_date_list, src_format)\n",
    "    return True\n",
    "\n",
    "def etl_report_one(src_bucket,tgt_bucket, date_list, columns, arg_date, target_key, trg_format, meta_file, src_format):\n",
    "    # Extract\n",
    "    df = extract(src_bucket, date_list)\n",
    "    # Transform\n",
    "    df = transform_report_one(df, columns, arg_date)\n",
    "    # Load\n",
    "    resutl = load(tgt_bucket, df, target_key, trg_format, meta_file, date_list, src_format)\n",
    "\n",
    "    return resutl\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer Helpers: No core application\n",
    "def get_date_list(bucket, arg_date, meta_file, src_format):\n",
    "    \"\"\"read object from s3 bucket filtered by Date\n",
    "\n",
    "    Args:\n",
    "        bucket (_type_): _description_\n",
    "        arg_date (_type_): _description_\n",
    "        src_format (_type_): _description_\n",
    "\n",
    "    Returns:boto3.resource('s3')\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
    "    max_date = datetime.strptime(arg_date, src_format).date() + timedelta(days=1) \n",
    "    try:\n",
    "        today = datetime.today().date() - relativedelta(years=1)\n",
    "        date_list = [(min_date + timedelta(days=x)).strftime(src_format) for x in range(0, (today-min_date).days + 1)]\n",
    "        df_meta = read_csv_to_df(bucket, meta_file)\n",
    "        diff_date_list = set(date_list) - set(df_meta.source_date)\n",
    "        if diff_date_list:\n",
    "            list_date = [date for date in sorted(diff_date_list) if date > min_date.strftime(src_format)]\n",
    "            min_date = min(list_date)\n",
    "        else:\n",
    "            min_date = datetime.datetime(2200, 1, 1)\n",
    "            list_date = []\n",
    "    except Exception as exp:\n",
    "        list_date = [(min_date + timedelta(days=x)).strftime(src_format) for x in range(0, (max_date - min_date).days + 1)]\n",
    "        min_date = arg_date\n",
    "    return list_date, min_date\n",
    "\n",
    "def update_meta_file(bucket, meta_file, extract_date_list, src_format):\n",
    "    df_new = pd.DataFrame(\n",
    "        data={\n",
    "            'source_date': extract_date_list,\n",
    "            'datetime_of_processing': (\n",
    "                [datetime.today().date().strftime(src_format)] * len(extract_date_list)\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    df_old = read_csv_to_df(bucket, meta_file)\n",
    "    \n",
    "    df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "    \n",
    "    write_df_to_s3_csv(bucket, df, meta_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point\n",
    "\n",
    "def main():\n",
    "    \"\"\"\"\"\"\n",
    "    # paramters\n",
    "    arg_date = \"2022-03-22\"\n",
    "    src_format = '%Y-%m-%d'\n",
    "    name_src_bucket = 'xetra-1234'\n",
    "    name_tgt_bucket = 'xetra-data-etl'\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    key = \"xetra_daily_report_\"\n",
    "    tgt_format = \".parquet\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # load paramters\n",
    "    load_config()\n",
    "\n",
    "    # connection to s3\n",
    "    \n",
    "    s3 = connect_boto3()\n",
    "\n",
    "    tgt_bucket = s3.Bucket(name_tgt_bucket)\n",
    "    src_bucket = s3.Bucket(name_src_bucket)\n",
    "    # read objects\n",
    "    date_list, min_date = get_date_list(tgt_bucket, arg_date, meta_file, src_format)\n",
    "    # pipeline \n",
    "    etl_report_one(src_bucket, tgt_bucket, date_list, columns, arg_date, key, tgt_format, meta_file, src_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432592/3941252504.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['OpeningPrice'] = (\n",
      "/tmp/ipykernel_432592/3941252504.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ClosingPrice'] = (\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv(\"ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"SECRET_ACCESS_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tgt_bucket = 'xetra-data-etl'\n",
    "meta_file = \"meta_file.csv\"\n",
    "bucket = s3.Bucket(name_tgt_bucket) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_date</th>\n",
       "      <th>datetime_of_processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>2023-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>2023-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>2023-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>2021-04-23 12:33:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>2021-04-21 12:30:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_date datetime_of_processing\n",
       "0  2022-03-22             2023-03-27\n",
       "1  2022-03-23             2023-03-27\n",
       "2  2022-03-25             2023-03-27\n",
       "3  2022-03-27             2023-03-27\n",
       "4  2022-03-26    2021-04-23 12:33:23\n",
       "5  2022-03-24    2021-04-21 12:30:21"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = read_csv_to_df(bucket, meta_file)\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   source_date             6 non-null      object\n",
      " 1   datetime_of_processing  6 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# deutsche-boerse-xetra-pds xetra-1234\n",
    "df_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[s3.ObjectSummary(bucket_name='xetra-data-etl', key='meta_file.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230325_183831.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230326_013108.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230326_150851.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230326_162413.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230326_162505.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_160816.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_162446.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_162530.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_162800.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_162905.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_163006.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_170131.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_170241.parquet'),\n",
       " s3.ObjectSummary(bucket_name='xetra-data-etl', key='xetra_daily_report_20230327_170330.parquet')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj for obj in bucket.objects.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimun_price_eur</th>\n",
       "      <th>maxmun_price_eur</th>\n",
       "      <th>daily_traded_volumne</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>37.80</td>\n",
       "      <td>37.80</td>\n",
       "      <td>37.80</td>\n",
       "      <td>37.80</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>37.40</td>\n",
       "      <td>37.60</td>\n",
       "      <td>37.40</td>\n",
       "      <td>37.60</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>36.80</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.80</td>\n",
       "      <td>119</td>\n",
       "      <td>-3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.17</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.09</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.09</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.08</td>\n",
       "      <td>14832</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>23.96</td>\n",
       "      <td>23.63</td>\n",
       "      <td>23.63</td>\n",
       "      <td>23.96</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>23.17</td>\n",
       "      <td>23.94</td>\n",
       "      <td>23.17</td>\n",
       "      <td>23.94</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>24.71</td>\n",
       "      <td>24.06</td>\n",
       "      <td>24.06</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9758 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0     AT000000STR1  2022-03-22              37.80              37.80   \n",
       "1     AT000000STR1  2022-03-23              37.40              37.60   \n",
       "2     AT000000STR1  2022-03-25              36.80              36.40   \n",
       "3     AT00000FACC2  2022-03-22               8.16               8.10   \n",
       "4     AT00000FACC2  2022-03-23               8.07               8.09   \n",
       "...            ...         ...                ...                ...   \n",
       "9753  XS2434891219  2022-03-23               3.81               3.87   \n",
       "9754  XS2434891219  2022-03-25               3.98               4.05   \n",
       "9755  XS2437455608  2022-03-22              23.96              23.63   \n",
       "9756  XS2437455608  2022-03-23              23.17              23.94   \n",
       "9757  XS2437455608  2022-03-25              24.71              24.06   \n",
       "\n",
       "      minimun_price_eur  maxmun_price_eur  daily_traded_volumne  \\\n",
       "0                 37.80             37.80                     0   \n",
       "1                 37.40             37.60                    30   \n",
       "2                 36.40             36.80                   119   \n",
       "3                  8.01              8.17                   166   \n",
       "4                  8.07              8.09                    25   \n",
       "...                 ...               ...                   ...   \n",
       "9753               3.81              3.87                     0   \n",
       "9754               3.96              4.08                 14832   \n",
       "9755              23.63             23.96                     0   \n",
       "9756              23.17             23.94                     0   \n",
       "9757              24.06             24.71                     0   \n",
       "\n",
       "      change_prev_closing_%  \n",
       "0                       NaN  \n",
       "1                     -0.53  \n",
       "2                     -3.19  \n",
       "3                       NaN  \n",
       "4                     -0.12  \n",
       "...                     ...  \n",
       "9753                   0.03  \n",
       "9754                   4.86  \n",
       "9755                    NaN  \n",
       "9756                   1.29  \n",
       "9757                   0.53  \n",
       "\n",
       "[9758 rows x 8 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bu = s3.Bucket(target_bucket)\n",
    "# \n",
    "csv_obj = bucket.Object(key='xetra_daily_report_20230327_163006.parquet').get().get(\"Body\").read()\n",
    "data = BytesIO(csv_obj)\n",
    "df = pd.read_parquet(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-training-skill-fXPABlwS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
